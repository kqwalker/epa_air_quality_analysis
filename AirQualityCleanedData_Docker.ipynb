{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv files\n",
    "\n",
    "# specify the path to csv files\n",
    "path=\"CSV_Folder\"\n",
    "\n",
    "files=glob.glob(path + \"/*.csv\")\n",
    "# defining an empty list to store \n",
    "# content\n",
    "data_frame = pd.DataFrame()\n",
    "content = []\n",
    "\n",
    "# checking all the csv files in the \n",
    "# specified path\n",
    "for filename in files:\n",
    "  \n",
    "    # reading content of csv file\n",
    "    # content.append(filename)\n",
    "    df = pd.read_csv(filename, index_col=None)\n",
    "    content.append(df)\n",
    "\n",
    "# converting content to data frame\n",
    "df_combined = pd.concat(content)\n",
    "\n",
    "display(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data into a geopandas dataframe\n",
    "df_aq=gpd.GeoDataFrame(df_combined, geometry=gpd.points_from_xy(df_combined['Site Longitude'],df_combined['Site Latitude']), crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_aq.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a map to see sensor locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create copy of data\n",
    "df_aq_sites=df_aq.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary of sensor site locations\n",
    "df_aq_sites=df_aq_sites[['Site ID','Local Site Name','CBSA Name', 'County','State', 'State FIPS Code', 'County FIPS Code', 'geometry']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aq_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map using leafmap\n",
    "m=leafmap.Map()\n",
    "m.add_gdf(df_aq_sites, layer_name=\"Sensor Sites\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export air sensors as a geopackage\n",
    "file_name_sensor_location=\"aq_sensor_site_locations\" #this is the file name\n",
    "df_aq_sites.to_file(file_name_sensor_location+\".gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the index is a datetime index\n",
    "df_aq['Date_analysis'] = pd.to_datetime(df_aq['Date'])\n",
    "\n",
    "# Extract year from the date index\n",
    "df_aq['Year'] = df_aq['Date_analysis'].dt.year\n",
    "\n",
    "# Extract Month\n",
    "df_aq['month'] = df_aq['Date_analysis'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_to_season={\n",
    "    1: 'Winter',\n",
    "    2: 'Winter',\n",
    "    3: 'Spring',\n",
    "    4: 'Spring',\n",
    "    5: 'Spring',\n",
    "    6: 'Summer',\n",
    "    7: 'Summer',\n",
    "    8: 'Summer',\n",
    "    9: 'Fall',\n",
    "    10: 'Fall',\n",
    "    11: 'Fall',\n",
    "    12: 'Winter',\n",
    "    }\n",
    "    \n",
    "df_aq['season'] = df_aq['month'].map(month_to_season) #add seasons based on month\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_aq.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create categorical column based on aqs parameter description\n",
    "\n",
    "df_aq_messy=df_aq.copy()\n",
    "\n",
    "df_aq_messy['AQS Parameter Description']=pd.Categorical(df_aq_messy['AQS Parameter Description'], categories=['PM2.5 - Local Conditions','Acceptable PM2.5 AQI & Speciation Mass'], ordered=True)\n",
    "\n",
    "\n",
    "#sort values based on site ID, date, and aqs parameter code\n",
    "#drop repeat days based on aqs parameter description\n",
    "\n",
    "df_aqi_cleaned=df_aq.sort_values(by=['Site ID','Date_analysis','AQS Parameter Description']).drop_duplicates(subset=['Site ID','Date_analysis']).sort_index()\n",
    "\n",
    "display(df_aqi_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see how many duplicates were removed from the data\n",
    "print('original dataframe count: ', df_aq['Date'].count())\n",
    "print('cleaned dataframe count: ', df_aqi_cleaned['Date'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing any negative PM2.5 values into 0\n",
    "df_aqi_cleaned['Daily Mean PM2.5 Concentration']=df_aqi_cleaned['Daily Mean PM2.5 Concentration'].apply(lambda x: 0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aqi_categories(aqi_breakpoints):\n",
    "    '''\n",
    "    This function creates the EPA AQI Categories based on the AQI breakpoints. This is based on documentation found here:\n",
    "    https://document.airnow.gov/technical-assistance-document-for-the-reporting-of-daily-air-quailty.pdf, which was accessed 12/18/2024.\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    aqi: integer\n",
    "        The calculated AQI value.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    string\n",
    "        The different AQI categories based on the AQI breakpoints are returned.\n",
    "    \n",
    "    '''\n",
    "    if(aqi_breakpoints<=50):\n",
    "        return \"Good\"\n",
    "    elif(51<=aqi_breakpoints<=100):\n",
    "        return \"Moderate\"\n",
    "    elif(101<=aqi_breakpoints<=150):\n",
    "        return \"Unhealthy for Sensitive Individuals\"\n",
    "    elif(151<=aqi_breakpoints<=200):\n",
    "        return \"Unhealthy\"\n",
    "    elif(201<=aqi_breakpoints<=300):\n",
    "        return \"Very Unhealthy\"\n",
    "    elif(301<=aqi_breakpoints):\n",
    "        return \"Hazardous\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add air quality index values using the data's Daily AQI Value\n",
    "df_aqi_cleaned['aqi_category']=df_aqi_cleaned['Daily AQI Value'].apply(aqi_categories) #apply AQI categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aqi_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into a geopandas dataframe\n",
    "df_aqi_cleaned=gpd.GeoDataFrame(df_aqi_cleaned, geometry='geometry', crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned dataset as a geopackage\n",
    "file_name_cleaned_data=\"cleaned_air_quality_data\" #this is the file name\n",
    "df_aqi_cleaned.to_file(file_name_cleaned_data+\".gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating seasonal stats\n",
    "\n",
    "season_stats = (\n",
    "    df_aqi_cleaned.groupby(['Site ID', 'season', 'Units', 'Local Site Name', 'CBSA Name',\n",
    "       'State FIPS Code', 'State', 'County FIPS Code', 'County',\n",
    "       'Site Latitude', 'Site Longitude', 'geometry'])['Daily Mean PM2.5 Concentration']\n",
    "      .agg(['min', 'max', 'median', 'mean'])\n",
    "      .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aqi_categories_pm(arithmetic_mean):\n",
    "    '''\n",
    "    This function creates the EPA AQI Categories based on the PM 2.5 breakpoints. This is based on documentation found here:\n",
    "    https://document.airnow.gov/technical-assistance-document-for-the-reporting-of-daily-air-quailty.pdf, which was accessed 12/18/2024.\n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    arithmetic_mean: integer\n",
    "        The calculated PM 2.5 value.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    string\n",
    "        The different AQI categories based on the PM 2.5 breakpoints are returned.\n",
    "    \n",
    "    '''\n",
    "    if(arithmetic_mean<=9.0):\n",
    "        return \"Good\"\n",
    "    elif(9.1<=arithmetic_mean<=35.4):\n",
    "        return \"Moderate\"\n",
    "    elif(35.5<=arithmetic_mean<=55.4):\n",
    "        return \"Unhealthy for Sensitive Individuals\"\n",
    "    elif(55.5<=arithmetic_mean<=125.4):\n",
    "        return \"Unhealthy\"\n",
    "    elif(125.5<=arithmetic_mean<=225.4):\n",
    "        return \"Very Unhealthy\"\n",
    "    elif(225.5<=arithmetic_mean):\n",
    "        return \"Hazardous\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the AQI categories based on the min, median, mean, and max PM 2.5 values\n",
    "season_stats['min_aqi_category']=season_stats['min'].apply(aqi_categories_pm) #apply AQI categories\n",
    "season_stats['median_aqi_category']=season_stats['median'].apply(aqi_categories_pm) #apply AQI categories\n",
    "season_stats['mean_aqi_category']=season_stats['mean'].apply(aqi_categories_pm) #apply AQI categories\n",
    "season_stats['max_aqi_category']=season_stats['max'].apply(aqi_categories_pm) #apply AQI categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert season stats into geopandas dataframe\n",
    "season_stats_gdf=gpd.GeoDataFrame(season_stats, geometry='geometry', crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_stats_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data as a geopackage\n",
    "seasonal_stats_file_name=\"seasonal_air_quality_analysis\"\n",
    "season_stats_gdf.to_file(seasonal_stats_file_name+\".gpkg\", driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
